# ğŸ“‹ å®æ–½è®¡åˆ’ - APIæ‰¹é‡æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

> **åŠŸèƒ½ID**: perf-001-batch-query
> **åŸºäº**: spec.md + æ¶æ„å¸ˆå®¡æ ¸å»ºè®®
> **é¢„è®¡å·¥ä½œé‡**: 45åˆ†é’Ÿ
> **é£é™©ç­‰çº§**: ä½

---

## ğŸ¯ å®æ–½ç›®æ ‡

å°† `/api/feed` å’Œ `/api/intelligence` æ¥å£å»¶è¿Ÿä»60ç§’é™ä½åˆ°15-20ç§’ï¼Œé€šè¿‡æ¶ˆé™¤N+1æŸ¥è¯¢é—®é¢˜ã€‚

---

## ğŸ“¦ å¯å¤ç”¨ç»„ä»¶æ¸…å•

**æ£€æŸ¥ç»“æœ**: æ— éœ€å¤ç”¨ç°æœ‰ç»„ä»¶

| ç±»åˆ« | æ£€æŸ¥ç»“æœ | è¯´æ˜ |
|:---|:---|:---|
| **åç«¯å‡½æ•°** | âŒ ä¸å¤ç”¨ | éœ€æ–°å¢æ‰¹é‡æŸ¥è¯¢å‡½æ•° |
| **æ•°æ®åº“å‡½æ•°** | âœ… å¤ç”¨ | å¤ç”¨ `db_conn()`, `get_placeholder()` |
| **å·¥å…·å‡½æ•°** | âœ… å¤ç”¨ | å¤ç”¨ `json.loads()` è§£æé€»è¾‘ |

**æ–°å¢ç»„ä»¶**:
1. `_parse_analysis_row()` - é€šç”¨æ•°æ®è§£æå‡½æ•°
2. `get_cached_analysis_batch()` - æ‰¹é‡æŸ¥è¯¢å‡½æ•°

---

## ğŸ—‚ï¸ æ–‡ä»¶ä¿®æ”¹æ¸…å•

| æ–‡ä»¶ | ä¿®æ”¹ç±»å‹ | è¯´æ˜ |
|:---|:---|:---|
| `backend/main.py` | ä¿®æ”¹ | æ–°å¢2ä¸ªå‡½æ•°ï¼Œä¿®æ”¹1ä¸ªå‡½æ•° |

---

## ğŸ“ å®æ–½æ­¥éª¤

### æ­¥éª¤1: æå–å…¬å…±è§£æé€»è¾‘ (10åˆ†é’Ÿ)

**ä½ç½®**: `backend/main.py` ç¬¬370è¡Œé™„è¿‘ï¼ˆ`get_cached_analysis` å‡½æ•°ä¹‹å‰ï¼‰

**æ–°å¢å‡½æ•°**:
```python
def _parse_analysis_row(row) -> Optional[Dict[str, Any]]:
    """
    è§£ææ•°æ®åº“æŸ¥è¯¢ç»“æœè¡Œä¸ºåˆ†ææ•°æ®å­—å…¸

    Args:
        row: æ•°æ®åº“æŸ¥è¯¢ç»“æœè¡Œï¼ˆæ”¯æŒdictæˆ–tupleæ ¼å¼ï¼‰

    Returns:
        è§£æåçš„åˆ†ææ•°æ®ï¼Œå¦‚æœæ— æœ‰æ•ˆæ•°æ®åˆ™è¿”å›None
        æ ¼å¼: {
            'polarity': str,
            'impacts': List[Dict],
            'opinion': str,
            'tags': List[str]
        }
    """
    # å…¼å®¹dictå’Œtupleä¸¤ç§rowæ ¼å¼
    if isinstance(row, dict):
        polarity = row.get("ai_polarity")
        impacts_str = row.get("ai_impacts")
        opinion = row.get("ai_opinion", "")
        tags_str = row.get("ai_tags")
    else:
        polarity = row[0] if len(row) > 0 else None
        impacts_str = row[1] if len(row) > 1 else None
        opinion = (row[2] if len(row) > 2 else "") or ""
        tags_str = row[3] if len(row) > 3 else None

    # éªŒè¯æœ‰æ•ˆæ€§
    if not polarity:
        return None

    # è§£æJSONå­—æ®µ
    try:
        return {
            "polarity": polarity,
            "impacts": json.loads(impacts_str) if impacts_str else [],
            "opinion": opinion,
            "tags": json.loads(tags_str) if tags_str else []
        }
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
        return None
```

**éªŒæ”¶**:
- [ ] å‡½æ•°èƒ½å¤„ç†dictæ ¼å¼row
- [ ] å‡½æ•°èƒ½å¤„ç†tupleæ ¼å¼row
- [ ] polarityä¸ºç©ºæ—¶è¿”å›None
- [ ] JSONè§£æå¼‚å¸¸æ—¶è¿”å›None

---

### æ­¥éª¤2: é‡æ„ç°æœ‰å‡½æ•°ä½¿ç”¨å…¬å…±é€»è¾‘ (5åˆ†é’Ÿ)

**ä¿®æ”¹**: `get_cached_analysis` å‡½æ•°ï¼ˆ371-409è¡Œï¼‰

**å½“å‰ä»£ç **:
```python
def get_cached_analysis(source_url: str) -> Optional[Dict[str, Any]]:
    """è·å–ç¼“å­˜çš„ AI åˆ†æç»“æœ"""
    if not source_url:
        return None

    try:
        ph = get_placeholder()
        with db_conn() as conn:
            cur = conn.cursor()
            cur.execute(f"""
                SELECT ai_polarity, ai_impacts, ai_opinion, ai_tags, ai_analyzed_at
                FROM raw_articles
                WHERE source_url = {ph} AND ai_analyzed_at IS NOT NULL
            """, (source_url,))
            row = cur.fetchone()

            if row:
                # ... 20è¡Œè§£æé€»è¾‘ ...
                return {...}
    except Exception as e:
        print(f"âš ï¸ è¯»å– AI ç¼“å­˜å¤±è´¥: {e}")

    return None
```

**é‡æ„å**:
```python
def get_cached_analysis(source_url: str) -> Optional[Dict[str, Any]]:
    """è·å–ç¼“å­˜çš„ AI åˆ†æç»“æœ"""
    if not source_url:
        return None

    try:
        ph = get_placeholder()
        with db_conn() as conn:
            cur = conn.cursor()
            cur.execute(f"""
                SELECT ai_polarity, ai_impacts, ai_opinion, ai_tags
                FROM raw_articles
                WHERE source_url = {ph} AND ai_analyzed_at IS NOT NULL
            """, (source_url,))
            row = cur.fetchone()

            if row:
                return _parse_analysis_row(row)  # âœ… ä½¿ç”¨å…¬å…±å‡½æ•°

    except Exception as e:
        print(f"âš ï¸ è¯»å– AI ç¼“å­˜å¤±è´¥: {e}")

    return None
```

**éªŒæ”¶**:
- [ ] å‡½æ•°è¡Œæ•°å‡å°‘çº¦15è¡Œ
- [ ] åŠŸèƒ½ä¿æŒä¸å˜ï¼ˆé€šè¿‡æµ‹è¯•éªŒè¯ï¼‰

---

### æ­¥éª¤3: æ–°å¢æ‰¹é‡æŸ¥è¯¢å‡½æ•° (15åˆ†é’Ÿ)

**ä½ç½®**: `backend/main.py` `get_cached_analysis` å‡½æ•°ä¹‹å

**æ–°å¢å‡½æ•°**:
```python
def get_cached_analysis_batch(
    source_urls: List[str],
    batch_size: int = 100
) -> Dict[str, Dict[str, Any]]:
    """
    æ‰¹é‡è·å–AIåˆ†æç¼“å­˜ï¼ˆä¼˜åŒ–N+1æŸ¥è¯¢ï¼‰

    Args:
        source_urls: æ–‡ç« URLåˆ—è¡¨
        batch_size: å•æ¬¡æŸ¥è¯¢çš„æœ€å¤§URLæ•°é‡ï¼Œé»˜è®¤100

    Returns:
        URLåˆ°åˆ†ææ•°æ®çš„æ˜ å°„å­—å…¸
        æ ¼å¼: {
            'url1': {'polarity': 'positive', 'impacts': [...], ...},
            'url2': {'polarity': 'neutral', 'impacts': [...], ...}
        }

    Note:
        - åªè¿”å›æœ‰ç¼“å­˜çš„URLï¼Œæœªç¼“å­˜çš„ä¸åœ¨ç»“æœä¸­
        - è‡ªåŠ¨åˆ†æ‰¹æŸ¥è¯¢ï¼Œé˜²æ­¢å•æ¬¡INå‚æ•°è¿‡å¤š
    """
    if not source_urls:
        return {}

    all_results = {}

    # åˆ†æ‰¹å¤„ç†ï¼Œé˜²æ­¢å•æ¬¡æŸ¥è¯¢å‚æ•°è¿‡å¤š
    for i in range(0, len(source_urls), batch_size):
        batch = source_urls[i:i + batch_size]

        try:
            ph = get_placeholder()
            with db_conn() as conn:
                cur = conn.cursor()

                # æ„å»ºINæŸ¥è¯¢
                placeholders = ','.join([ph] * len(batch))
                query = f"""
                    SELECT source_url, ai_polarity, ai_impacts,
                           ai_opinion, ai_tags
                    FROM raw_articles
                    WHERE source_url IN ({placeholders})
                      AND ai_analyzed_at IS NOT NULL
                """

                cur.execute(query, batch)

                # è§£æç»“æœ
                for row in cur.fetchall():
                    # æå–source_url
                    source_url = row[0] if isinstance(row, tuple) else row['source_url']

                    # è§£æåˆ†ææ•°æ®ï¼ˆè·³è¿‡ç¬¬ä¸€åˆ—source_urlï¼‰
                    analysis_row = row[1:] if isinstance(row, tuple) else row
                    analysis = _parse_analysis_row(analysis_row)

                    if analysis:
                        all_results[source_url] = analysis

        except Exception as e:
            print(f"âš ï¸ æ‰¹é‡è·å–ç¼“å­˜å¤±è´¥ (batch {i//batch_size + 1}): {e}")
            # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œä¸ä¸­æ–­

    print(f"ğŸ“¦ æ‰¹é‡ç¼“å­˜æŸ¥è¯¢: {len(source_urls)}ä¸ªURL, å‘½ä¸­{len(all_results)}ä¸ª")
    return all_results
```

**éªŒæ”¶**:
- [ ] èƒ½å¤„ç†ç©ºåˆ—è¡¨è¾“å…¥
- [ ] èƒ½å¤„ç†è¶…è¿‡batch_sizeçš„URLåˆ—è¡¨
- [ ] è¿”å›æ ¼å¼æ­£ç¡®: Dict[str, Dict]
- [ ] å¼‚å¸¸æ—¶è¿”å›ç©ºå­—å…¸ï¼Œä¸å½±å“ä¸»æµç¨‹
- [ ] æ‰“å°æœ‰ç”¨çš„è°ƒè¯•ä¿¡æ¯

---

### æ­¥éª¤4: ä¿®æ”¹build_intelligence_cardsä½¿ç”¨æ‰¹é‡æŸ¥è¯¢ (15åˆ†é’Ÿ)

**ä½ç½®**: `backend/main.py` ç¬¬444-525è¡Œ

**å½“å‰é€»è¾‘**:
```python
def build_intelligence_cards(...):
    # 1. æ”¶é›†pending_tasks
    pending_tasks = [...]

    # 2. å¤šçº¿ç¨‹å¤„ç†
    def process_one(task):
        cached = get_cached_analysis(source_url)  # âŒ N+1æŸ¥è¯¢
        ...
```

**ä¼˜åŒ–åé€»è¾‘**:
```python
def build_intelligence_cards(...):
    # 1. æ”¶é›†pending_tasks
    pending_tasks = [...]

    # 2. âœ… æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰ç¼“å­˜ï¼ˆå…³é”®ä¼˜åŒ–ç‚¹ï¼‰
    source_urls = [task[0].get("source_url") for task in pending_tasks
                   if task[0].get("source_url")]
    cached_analyses = get_cached_analysis_batch(source_urls) if not skip_ai else {}

    # 3. å¤šçº¿ç¨‹å¤„ç†
    def process_one(task):
        source_url = normalized.get("source_url")

        if skip_ai:
            analysis = {...}
        else:
            # âœ… ä»å­—å…¸æŸ¥æ‰¾ï¼Œä¸æŸ¥æ•°æ®åº“
            cached = cached_analyses.get(source_url)
            if cached:
                analysis = cached
                print(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜: {normalized['title'][:30]}...")
            else:
                print(f"ğŸ¤– AI åˆ†æä¸­: {normalized['title'][:30]}...")
                analysis = analyze_article(...)
                if source_url and analysis.get("polarity"):
                    save_analysis_cache(source_url, analysis)
        ...
```

**å…·ä½“ä¿®æ”¹ä½ç½®**:
1. åœ¨ç¬¬465è¡Œï¼ˆ`pending_tasks = pending_tasks[:limit]`ï¼‰ä¹‹åæ’å…¥æ‰¹é‡æŸ¥è¯¢
2. ä¿®æ”¹ç¬¬481è¡Œï¼ˆ`cached = get_cached_analysis(source_url)`ï¼‰ä¸ºå­—å…¸æŸ¥æ‰¾

**éªŒæ”¶**:
- [ ] æ‰¹é‡æŸ¥è¯¢åœ¨å¤šçº¿ç¨‹å¤–æ‰§è¡Œï¼ˆç¡®ä¿åªæŸ¥1æ¬¡ï¼‰
- [ ] process_oneå‡½æ•°ä»å­—å…¸æŸ¥æ‰¾ç¼“å­˜
- [ ] ä¿æŒåŸæœ‰å¹¶å‘é€»è¾‘ä¸å˜
- [ ] æ—¥å¿—è¾“å‡ºæ¸…æ™°ï¼ˆæ˜¾ç¤ºç¼“å­˜å‘½ä¸­æƒ…å†µï¼‰

---

## âœ… éªŒè¯æ¸…å•

### åŠŸèƒ½éªŒè¯
- [ ] `/api/feed` è¿”å›æ•°æ®æ ¼å¼æ­£ç¡®
- [ ] `/api/intelligence` è¿”å›æ•°æ®æ ¼å¼æ­£ç¡®
- [ ] ç¼“å­˜å‘½ä¸­æ—¶ä¸è°ƒç”¨AI
- [ ] ç¼“å­˜æœªå‘½ä¸­æ—¶æ­£å¸¸è°ƒç”¨AIå¹¶ä¿å­˜

### æ€§èƒ½éªŒè¯
- [ ] `/api/feed` TTFB < 20ç§’
- [ ] `/api/intelligence` TTFB < 20ç§’
- [ ] æ•°æ®åº“æŸ¥è¯¢æ—¥å¿—æ˜¾ç¤ºä»…1æ¬¡æ‰¹é‡æŸ¥è¯¢
- [ ] æ‰¹é‡æŸ¥è¯¢100ä¸ªURLè€—æ—¶ < 300ms

### ä»£ç è´¨é‡
- [ ] æ— PEP8è­¦å‘Š
- [ ] ç±»å‹æç¤ºå®Œæ•´
- [ ] å‡½æ•°æ–‡æ¡£å®Œæ•´
- [ ] æ— ä»£ç é‡å¤

---

## ğŸ”„ å›æ»šè®¡åˆ’

å¦‚æœä¼˜åŒ–åå‡ºç°é—®é¢˜ï¼Œå›æ»šæ­¥éª¤ï¼š

1. **ä¿ç•™æ–°å¢å‡½æ•°** - `_parse_analysis_row` å’Œ `get_cached_analysis_batch` ä¿ç•™ï¼Œä¸å½±å“ç³»ç»Ÿ
2. **æ¢å¤build_intelligence_cards** - å°†æ‰¹é‡æŸ¥è¯¢æ”¹å›å•ä¸ªæŸ¥è¯¢
3. **éªŒè¯å›æ»š** - ç¡®è®¤æ¥å£è¿”å›æ­£å¸¸

**å›æ»šéš¾åº¦**: ä½ï¼ˆä»…éœ€æ¢å¤1ä¸ªå‡½æ•°çš„è°ƒç”¨æ–¹å¼ï¼‰

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹è¿› |
|:---|:---|:---|:---|
| æ•°æ®åº“æŸ¥è¯¢æ¬¡æ•° | 20æ¬¡ | 1æ¬¡ | 95% âœ… |
| æ•°æ®åº“æŸ¥è¯¢è€—æ—¶ | 4ç§’ | 0.2ç§’ | 95% âœ… |
| `/api/feed` TTFB | 60ç§’ | 15-20ç§’ | 67-75% âœ… |
| ä»£ç é‡å¤ | é«˜ | ä½ | æ¶ˆé™¤ âœ… |

---

## ğŸ“ å®æ–½å¤‡æ³¨

**æ³¨æ„äº‹é¡¹**:
1. ç¡®ä¿ `get_placeholder()` å‡½æ•°æ­£ç¡®è¿”å›PostgreSQLå ä½ç¬¦ `%s`
2. æ‰¹é‡æŸ¥è¯¢çš„SELECTå­—æ®µé¡ºåºå¿…é¡»ä¸è§£æé€»è¾‘ä¸€è‡´
3. æµ‹è¯•æ—¶æ³¨æ„è§‚å¯Ÿåç«¯æ—¥å¿—ä¸­çš„ç¼“å­˜å‘½ä¸­ä¿¡æ¯
4. å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå…ˆæ£€æŸ¥æ‰¹é‡æŸ¥è¯¢æ˜¯å¦åœ¨å¤šçº¿ç¨‹å¤–æ‰§è¡Œ

**ä¸‹ä¸€æ­¥**:
å®Œæˆæœ¬æ¬¡ä¼˜åŒ–åï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦è¿›è¡Œé˜¶æ®µ2ï¼ˆç¼“å­˜é¢„çƒ­ï¼‰ä¼˜åŒ–ã€‚
